{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oasst = pd.DataFrame(datasets.load_dataset(\"OpenAssistant/oasst1\")['train'])\n",
    "df_hh_rlhf = pd.DataFrame(datasets.load_dataset('Anthropic/hh-rlhf')['train'])\n",
    "df_alpaca = pd.DataFrame(datasets.load_dataset('tatsu-lab/alpaca')['train'])\n",
    "df_synthetic_instruct_gptj_pairwise = pd.DataFrame(datasets.load_dataset('Dahoas/synthetic-instruct-gptj-pairwise')['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Dataframe with all prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prompts = pd.DataFrame(columns=['prompt', 'prompt_origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hh_rlhf['prompt'] = df_hh_rlhf['chosen'].apply(lambda text: text[9:text.find('Assistant:')-2])\n",
    "df_hh_rlhf['prompt'] = df_hh_rlhf['prompt'].apply(lambda text: text.replace('\\n', ' '))\n",
    "df_hh_rlhf['prompt_origin'] = 'Anthropic/hh_rlhf'\n",
    "df_prompts = pd.concat([df_prompts, df_hh_rlhf[['prompt', 'prompt_origin']]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_synthetic_instruct_gptj_pairwise['prompt_origin'] = 'Dahoas/synthetic_instruct_gptj_pairwise'\n",
    "df_prompts = pd.concat([df_prompts, df_synthetic_instruct_gptj_pairwise[['prompt', 'prompt_origin']]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oasst = df_oasst[df_oasst['parent_id'].isnull()]\n",
    "df_oasst = df_oasst[df_oasst['lang'] == 'en']\n",
    "df_oasst['prompt'] = df_oasst['text']\n",
    "df_oasst['prompt_origin'] = 'OpenAssistant/oasst1'\n",
    "df_prompts = pd.concat([df_prompts, df_oasst[['prompt', 'prompt_origin']]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alpaca['instruction'] = df_alpaca['instruction'].apply(lambda text: text.replace('\\n', ' '))\n",
    "df_alpaca['input'] = df_alpaca['input'].apply(lambda text: text.replace('\\n', ' '))\n",
    "df_alpaca['input'] = df_alpaca['input'].apply(lambda text: text if text == '' else ': ' + text)\n",
    "df_alpaca['instruction'] = df_alpaca.apply(lambda row: row['instruction'][:-1] if row['input'] != '' and row['instruction'].endswith('.') else row['instruction'], axis=1)\n",
    "df_alpaca['prompt'] = df_alpaca['instruction'] + df_alpaca['input']\n",
    "df_alpaca['prompt_origin'] = 'tatsu-lab/alpaca'\n",
    "df_alpaca = df_alpaca[['prompt', 'prompt_origin']]\n",
    "df_prompts = pd.concat([df_prompts, df_alpaca[['prompt', 'prompt_origin']]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove prompt duplicates\n",
    "df_prompts = df_prompts.drop_duplicates(subset=['prompt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prompts = shuffle(df_prompts, random_state=42)\n",
    "df_prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prompt answering was conducted on the DFKI High-Performance-Computer Cluster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
